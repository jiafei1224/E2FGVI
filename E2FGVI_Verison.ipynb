{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZurXfq-F6jj"
      },
      "source": [
        "# Towards An <strong>E</strong>nd-to-<strong>E</strong>nd Framework for <strong>F</strong>low-<strong>G</strong>uided <strong>V</strong>ideo <strong>I</strong>npainting (CVPR 2022)\n",
        "\n",
        "In this demo, you can try to inpaint an example video through our framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDNKrW-NipaV"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4nBXDYiE-Y9",
        "outputId": "b3fd3e24-1553-41b0-fb40-6e0a4fe6399c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5.1+cu101 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.5.1+cu101\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.7.1.tar.gz (605 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.4/605.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv-full)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (6.0.1)\n",
            "Collecting yapf (from mmcv-full)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full) (3.16.2)\n",
            "Building wheels for collected packages: mmcv-full\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.7.1-cp310-cp310-linux_x86_64.whl size=30392895 sha256=7d3a8f437deaa70449f8465966700677964c8823fb68a294211795bc71d5c30b\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/9a/65/470be18e21a8f2d085a024f0731508273543de0b5f79d9ddd4\n",
            "Successfully built mmcv-full\n",
            "Installing collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.40.1\n",
            "Cloning into 'E2FGVI'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 345 (delta 48), reused 32 (delta 32), pack-reused 268\u001b[K\n",
            "Receiving objects: 100% (345/345), 36.75 MiB | 11.49 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Setup environment and code (may take some time)\n",
        "\n",
        "# Install Pytorch\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# Install MMCV\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n",
        "\n",
        "# prepare code\n",
        "import os\n",
        "CODE_DIR = 'E2FGVI'\n",
        "os.makedirs(f'./{CODE_DIR}')\n",
        "!git clone https://github.com/MCG-NKU/E2FGVI.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbTtlHMtLih_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91ab629-ec75-408a-a3bd-32567966364b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  E2FGVI_CVPR22_models.zip\n",
            "  inflating: E2FGVI-CVPR22.pth       \n",
            "  inflating: i3d_rgb_imagenet.pt     \n"
          ]
        }
      ],
      "source": [
        "#@title Download model with PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"release_model\")\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.makedirs(self.save_dir)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        downloaded = self.drive.CreateFile({'id':file_id})\n",
        "        downloaded.FetchMetadata(fetch_all=True)\n",
        "        downloaded.GetContentFile(file_dst)\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "path = {\"id\": \"1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9\", \"name\": \"E2FGVI_CVPR22_models.zip\"}\n",
        "downloader.download_file(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "\n",
        "os.chdir(downloader.save_dir)\n",
        "!unzip E2FGVI_CVPR22_models.zip\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv4fnTdaWe9K"
      },
      "source": [
        "# Define Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXPgvlRvF7oc"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import importlib\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# rc('animation', html='jshtml')\n",
        "\n",
        "from core.utils import to_tensors\n",
        "\n",
        "\n",
        "# global variables\n",
        "w, h = 432, 240\n",
        "ref_length = 10  # ref_step\n",
        "num_ref = -1\n",
        "neighbor_stride = 5\n",
        "\n",
        "\n",
        "# sample reference frames from the whole video\n",
        "def get_ref_index(f, neighbor_ids, length):\n",
        "    ref_index = []\n",
        "    if num_ref == -1:\n",
        "        for i in range(0, length, ref_length):\n",
        "            if i not in neighbor_ids:\n",
        "                ref_index.append(i)\n",
        "    else:\n",
        "        start_idx = max(0, f - ref_length * (num_ref//2))\n",
        "        end_idx = min(length, f + ref_length * (num_ref//2))\n",
        "        for i in range(start_idx, end_idx+1, ref_length):\n",
        "            if i not in neighbor_ids:\n",
        "                if len(ref_index) > num_ref:\n",
        "                    break\n",
        "                ref_index.append(i)\n",
        "    return ref_index\n",
        "\n",
        "\n",
        "# read frame-wise masks\n",
        "def read_mask(mpath):\n",
        "    masks = []\n",
        "    mnames = os.listdir(mpath)\n",
        "    mnames.sort()\n",
        "    for mp in mnames:\n",
        "        m = Image.open(os.path.join(mpath, mp))\n",
        "        m = m.resize((w, h), Image.NEAREST)\n",
        "        m = np.array(m.convert('L'))\n",
        "        m = np.array(m > 0).astype(np.uint8)\n",
        "        m = cv2.dilate(m, cv2.getStructuringElement(\n",
        "            cv2.MORPH_CROSS, (3, 3)), iterations=4)\n",
        "        masks.append(Image.fromarray(m*255))\n",
        "    return masks\n",
        "\n",
        "\n",
        "#  read frames from video\n",
        "def read_frame_from_videos(video_path):\n",
        "    vname = video_path\n",
        "    frames = []\n",
        "    lst = os.listdir(vname)\n",
        "    lst.sort()\n",
        "    fr_lst = [vname+'/'+name for name in lst]\n",
        "    for fr in fr_lst:\n",
        "        image = cv2.imread(fr)\n",
        "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        frames.append(image.resize((w, h)))\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyzbRrO19Y4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf87ce1e-a9f2-4023-c1f7-32118da98a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA7CC871cDnb"
      },
      "source": [
        "# Inpainting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFVXcD3COD7B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "4a726230-fc2d-417e-bd02-f8db97d33ec9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e05eb88d97f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set up models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.e2fgvi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInpaintGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/E2FGVI/release_model/E2FGVI-CVPR22.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# set up models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = importlib.import_module('model.e2fgvi')\n",
        "model = net.InpaintGenerator().to(device)\n",
        "ckpt_path = '/content/E2FGVI/release_model/E2FGVI-CVPR22.pth'\n",
        "data = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(data)\n",
        "print(f'Loading model from: {ckpt_path}')\n",
        "model.eval()\n",
        "\n",
        "# prepare dataset\n",
        "video_path = '/content/drive/MyDrive/frames'\n",
        "mask_path = '/content/drive/MyDrive/saved_masks'\n",
        "print(f'Loading videos and masks from: {video_path}')\n",
        "frames = read_frame_from_videos(video_path)\n",
        "\n",
        "\n",
        "video_length = len(frames)\n",
        "imgs = to_tensors()(frames).unsqueeze(0) * 2 - 1\n",
        "frames = [np.array(f).astype(np.uint8) for f in frames]\n",
        "\n",
        "\n",
        "masks = read_mask(mask_path)\n",
        "binary_masks = [np.expand_dims((np.array(m) != 0).astype(np.uint8), 2)\n",
        "                for m in masks]\n",
        "masks = to_tensors()(masks).unsqueeze(0)\n",
        "imgs, masks = imgs.to(device), masks.to(device)\n",
        "comp_frames = [None] * video_length\n",
        "\n",
        "# completing holes by e2fgvi\n",
        "print(f'Start test...')\n",
        "for f in tqdm(range(0, video_length, neighbor_stride)):\n",
        "    neighbor_ids = [i for i in range(max(0, f-neighbor_stride), min(video_length, f+neighbor_stride+1))]\n",
        "    ref_ids = get_ref_index(f, neighbor_ids, video_length)\n",
        "    selected_imgs = imgs[:1, neighbor_ids+ref_ids, :, :, :]\n",
        "    selected_masks = masks[:1, neighbor_ids+ref_ids, :, :, :]\n",
        "    with torch.no_grad():\n",
        "        masked_imgs = selected_imgs*(1-selected_masks)\n",
        "        pred_img, _ = model(masked_imgs, len(neighbor_ids))\n",
        "\n",
        "        pred_img = (pred_img + 1) / 2\n",
        "        pred_img = pred_img.cpu().permute(0, 2, 3, 1).numpy() * 255\n",
        "        for i in range(len(neighbor_ids)):\n",
        "            idx = neighbor_ids[i]\n",
        "            img = np.array(pred_img[i]).astype(\n",
        "                np.uint8)*binary_masks[idx] + frames[idx] * (1-binary_masks[idx])\n",
        "            if comp_frames[idx] is None:\n",
        "                comp_frames[idx] = img\n",
        "            else:\n",
        "                comp_frames[idx] = comp_frames[idx].astype(\n",
        "                    np.float32)*0.5 + img.astype(np.float32)*0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUt4uIY_biMg"
      },
      "source": [
        "## Show the inpainting video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkL4idywgySw"
      },
      "outputs": [],
      "source": [
        "height, width = 1920, 1080\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "ax.axis('off')\n",
        "imdata = ax.imshow(cv2.resize(comp_frames[0].astype(np.uint8), (width, height)), extent=[0, width, height, 0])\n",
        "\n",
        "def update(idx):\n",
        "    imdata.set_data(cv2.resize(comp_frames[idx].astype(np.uint8), (width, height)))\n",
        "\n",
        "anim = animation.FuncAnimation(fig, update, frames=len(frames), interval=50)\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-gx7TmQfhoO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}